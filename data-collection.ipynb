{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data analysis for Airline Models\n"
   ],
   "metadata": {
    "id": "bduoTFl0d7vs"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yijj9-Bsd2Cl",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "outputId": "d4c84bf1-1e02-44ea-f299-cd504512acd5"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://github.com/Speeb04/SDSS-Datathon/raw/refs/heads/main/Resources/Cases/Airline%20Tickets/airline_ticket_dataset.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df = df.loc[:, ~df.columns.str.contains(\"Unnamed\")]\n",
    "\n",
    "df.describe()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "LkYDpjjbfe64",
    "outputId": "3f6090f7-d7ae-4a79-d56c-035854818080"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"city1\"] = df[\"city1\"].str.replace(\" (Metropolitan Area)\", \"\")\n",
    "df[\"city2\"] = df[\"city2\"].str.replace(\" (Metropolitan Area)\", \"\")\n",
    "cities = set(df[\"city1\"].unique()) | set(df[\"city2\"].unique())\n",
    "cities"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPC_piCMw8tO",
    "outputId": "f36d9b16-cbec-49e8-c10f-1a07c81536fd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"carrier_lg\"].unique()"
   ],
   "metadata": {
    "id": "09mGgzrefn4u",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "62a8d4b3-829e-42d0-e4b6-5626e5f3bc13"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"carrier_low\"].unique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6KQxvPYsZZQ",
    "outputId": "a748c6e8-9238-43ce-9783-7b513ee1d8fa"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "full_service = ['DL', 'AS', 'UA', 'AA', 'B6', 'WN']\n",
    "low_cost = ['NK', 'F9', 'MX', 'XP', 'G4', 'SY', 'HA', '3M']\n",
    "\n",
    "hubs = ['Atlanta, GA', 'Minneapolis/St. Paul, MN', 'Detroit, MI', 'Salt Lake City, UT', 'Seattle, WA', 'New York City, NY', 'Boston, MA', 'Portland, OR',\n",
    "        'San Diego, CA', 'San Francisco, CA', 'Chicago, IL', 'Denver, CO', 'Houston, TX', 'Los Angeles, CA', 'Washington, DC', 'Dallas/Fort Worth, TX',\n",
    "        'Charlotte, NC', 'Miami, FL', 'Philadelphia, PA', 'Phoenix, AZ', 'Orlando, FL']"
   ],
   "metadata": {
    "id": "IfyFUnYFvF_P"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df['city1_is_hub'] = df['city1'].isin(hubs)\n",
    "df['city2_is_hub'] = df['city2'].isin(hubs)\n",
    "df['carrier_lg_is_full_service'] = df['carrier_lg'].isin(full_service)\n",
    "df['carrier_low_is_low_cost'] = df['carrier_low'].isin(low_cost)"
   ],
   "metadata": {
    "id": "Yt4Gct4j1xqx"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "FXUXKwF53B7F",
    "outputId": "fbef46cf-4390-480b-cebb-c8ff11606837"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df['carrier_lg_is_full_service'].unique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVyj1b237m_5",
    "outputId": "cf722213-8caa-4987-c3f4-aca49597c29c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df['carrier_low_is_low_cost'].unique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTnavMYU7yNu",
    "outputId": "6321b894-dabf-4b1a-9572-6b720f399739"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def addPopulation(main_df, population_data_df):\n",
    "    \"\"\"\n",
    "    Adds Population data to the main DataFrame based on citymarketid_1 and citymarketid_2.\n",
    "\n",
    "    Args:\n",
    "        main_df (pd.DataFrame): The original DataFrame.\n",
    "        population_data_df (pd.DataFrame): DataFrame containing 'city_name' and 'Population' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with Population data added.\n",
    "    \"\"\"\n",
    "    df_with_population = main_df.merge(population_data_df, left_on='city1', right_on='Geographic Area', how='left', suffixes=('', '_city1_pop'))\n",
    "    df_with_population = df_with_population.rename(columns={'population': 'Population_city1'})\n",
    "\n",
    "    df_with_population = df_with_population.merge(population_data_df, left_on='city2', right_on='Geographic Area', how='left', suffixes=('', '_city2_pop'))\n",
    "    df_with_population = df_with_population.rename(columns={'population': 'Population_city2'})\n",
    "    return df_with_population"
   ],
   "metadata": {
    "id": "8jM5PEc3oeOk"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "state_dict = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "}\n",
    "\n",
    "def truncate_state(df: pd.DataFrame, col_idx: str) -> None:\n",
    "    df[col_idx] = df[col_idx].apply(\n",
    "    lambda x: (\n",
    "        f\"{x.split(', ')[0]}, {state_dict.get(x.split(', ')[1], x.split(', ')[1])}\"\n",
    "        if isinstance(x, str) and ', ' in x\n",
    "        else x\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "id": "_HlQj9nqEbYU"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def is_hidden_subsequence(small, large):\n",
    "    it = iter(large)\n",
    "    return all(char in it for char in small)\n",
    "\n",
    "def find_city(GeoName: str) -> str:\n",
    "    GeoName_modified = GeoName.replace(\" \", \"\").replace(\"-\", \"\").replace(\"/\", \"\").replace(',',\"\").lower()\n",
    "    for named_city in cities:\n",
    "        # remove slashes, spaces from both datasets.\n",
    "        named_city_modified = named_city.replace(\" \", \"\").replace(\"-\", \"\").replace(\"/\", \"\").replace(',',\"\").lower()\n",
    "\n",
    "        if is_hidden_subsequence(named_city_modified, GeoName_modified):\n",
    "            return named_city\n",
    "\n",
    "    # Suppose that didn't work. T2- split each '/' to check for two cities\n",
    "    for named_city in cities:\n",
    "        if '/' in named_city:\n",
    "            cities_split = named_city.split('/')\n",
    "            for nested_city in cities_split:\n",
    "                nested_city_modified = nested_city.replace(\" \", \"\").replace(\"-\", \"\").replace(',',\"\").lower()\n",
    "                if is_hidden_subsequence(nested_city_modified, GeoName_modified):\n",
    "                    return named_city\n",
    "\n",
    "    return 'N/A'\n",
    "\n",
    "def pop_find_city(GeoName: str) -> str:\n",
    "    GeoName_modified = GeoName.replace(\" \", \"\").replace(\"-\", \"\").replace(\"/\", \"\").replace(',',\"\").lower()\n",
    "    for named_city in cities:\n",
    "        # remove slashes, spaces from both datasets.\n",
    "        named_city_modified = named_city.replace(\" \", \"\").replace(\"-\", \"\").replace(\"/\", \"\").replace(',',\"\").lower()\n",
    "\n",
    "        if is_hidden_subsequence(GeoName_modified, named_city_modified):\n",
    "            return named_city\n",
    "\n",
    "    return 'N/A'"
   ],
   "metadata": {
    "id": "SXgK6v33bSp5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "population_df = pd.read_csv(\"https://raw.githubusercontent.com/Speeb04/SDSS-Datathon/refs/heads/main/Resources/Cases/Airline%20Tickets/city_town_population_2024.csv\")\n",
    "population_df = population_df.dropna(subset=[\"Rank\"])\n",
    "\n",
    "mysterious_cities = [\"Valparaiso city, Florida\",\n",
    "                     \"Eagle city, Colorado\",\n",
    "                     \"Aspen city, Colorado\",\n",
    "                     \"Jackson city, Wyoming\",\n",
    "                     \"Nantucket city, Massachusetts\",\n",
    "                     \"Martha's Vineyard city, Massachusetts\",\n",
    "                     \"Latrobe, Pennsylvania\"]\n",
    "\n",
    "while len(mysterious_cities) > 0:\n",
    "    new_row = {\"Rank\": \"6969\", \"Geographic Area\": mysterious_cities.pop(), \"Estimate Base\": None, \"2020\": None, \"2021\": None, \"2022\": None, \"2023\": None, \"2024\": None}\n",
    "    population_df.loc[len(population_df)] = new_row\n",
    "\n",
    "\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" city\", \"\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" town\", \"\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" metropolitan\", \"\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" metro\", \"\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" government\", \"\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" (balance)\", \"\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\" City\", \"\")\n",
    "\n",
    "# One weird outlier\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\"Nashville-Davidson\", \"Nashville\")\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].str.replace(\"Louisville/Jefferson County\", \"Louisville\")\n",
    "\n",
    "truncate_state(population_df, 'Geographic Area')\n",
    "\n",
    "population_df['Geographic Area'] = population_df['Geographic Area'].apply(pop_find_city)\n",
    "\n",
    "population_df"
   ],
   "metadata": {
    "id": "Zm571-FLCrWV",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "1185d107-17e7-4af5-93d3-27864f71593e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pop_lut = {}\n",
    "\n",
    "for index, row in population_df.iterrows():\n",
    "    nested_dict = {}\n",
    "    for i in range(2020, 2025):\n",
    "        nested_dict[f'POP{i}'] = row[f'{i}']\n",
    "    pop_lut[row['Geographic Area']] = nested_dict\n",
    "\n",
    "pop_lut"
   ],
   "metadata": {
    "id": "Xd5U7SmDQyle",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6797ced2-e619-4065-a669-4692ec249031"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def addPOP(main_df, pop_lut):\n",
    "    for i in range(2020, 2025):\n",
    "        main_df[f\"city1_pop_{i}\"] = main_df[\"city1\"].map(\n",
    "            lambda city: pop_lut.get(city, {}).get(f\"POP{i}\")\n",
    "            if pd.notna(city) else city\n",
    "        )\n",
    "\n",
    "        main_df[f\"city2_pop_{i}\"] = main_df[\"city2\"].map(\n",
    "            lambda city: pop_lut.get(city, {}).get(f\"POP{i}\")\n",
    "            if pd.notna(city) else city\n",
    "        )"
   ],
   "metadata": {
    "id": "pUgJD6kqVqF1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "addPOP(df, pop_lut)\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "8x00ce9zV16d",
    "outputId": "c6f1b4e1-66db-4467-a53b-ebc5af358ea4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ~~WARNING: The CSV file has NOT been uploaded onto GitHub yet, as of <u>2:15 AM</u>.~~\n",
    "## ~~Ensure that the file has been uploaded, or else the code *cannot be interpreted*.~~\n",
    "\n",
    "<u>*Edit: As of 4:07 AM,*</u> the code below does NOT work for some inexplicable reason. It works fine on my local machine, so I exported that local CSV and added the population data onto it.\n",
    "\n",
    "Why the code below works any differently, I have <u>*no clue.*</u>"
   ],
   "metadata": {
    "id": "p_X3V-sOP9Xl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gdp_df = pd.read_csv(\"https://raw.githubusercontent.com/Speeb04/SDSS-Datathon/refs/heads/main/Resources/Cases/Airline%20Tickets/gdp_metro_area.csv\")\n",
    "gdp_df = gdp_df.drop(0) # remove US from dataset\n",
    "gdp_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pCC4rUK1P33H",
    "outputId": "7094b505-139b-4cf9-f19b-0b5302e06248"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "gdp_df['GeoName'] = gdp_df['GeoName'].str.replace(\" (Metropolitan Statistical Area)\", \"\")\n",
    "gdp_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "TroIRw7dQdYC",
    "outputId": "6c4ba6eb-aaa5-432f-c218-9f1adaeb3979"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def rename_gdp_df(gdp_df: pd.DataFrame) -> None:  # in place mutation\n",
    "    gdp_df['GeoName'] = gdp_df['GeoName'].apply(find_city)"
   ],
   "metadata": {
    "id": "lsw2FnknQiB3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "rename_gdp_df(gdp_df)\n",
    "gdp_df"
   ],
   "metadata": {
    "id": "auUHfE_AQj0C",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "outputId": "8a79b4e5-a006-4134-88cf-b33791d80bff"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "gdp_lut = {}\n",
    "\n",
    "for index, row in gdp_df.iterrows():\n",
    "    nested_dict = {}\n",
    "    for i in range(2001, 2019):\n",
    "        nested_dict[f'GDP{i}'] = row[f'{i}']\n",
    "    gdp_lut[row['GeoName']] = nested_dict\n",
    "\n",
    "gdp_lut"
   ],
   "metadata": {
    "id": "Xipcmrc5QlX7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "669f9bf9-9180-4061-e9d1-ecb1908c356e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def addGDP(main_df, gdp_lut):\n",
    "    for i in range(2001, 2019):\n",
    "        main_df[f\"city1_gdp_{i}\"] = main_df[\"city1\"].map(\n",
    "            lambda city: gdp_lut[city][f\"GDP{i}\"])\n",
    "        main_df[f\"city2_gdp_{i}\"] = main_df[\"city2\"].map(\n",
    "            lambda city: gdp_lut[city][f\"GDP{i}\"])"
   ],
   "metadata": {
    "id": "6aat2LQHQqAb"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "addGDP(df, gdp_lut)\n",
    "df"
   ],
   "metadata": {
    "id": "Z0ZL8IAjQwup",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "outputId": "14c732c8-d453-4772-e8c6-174b160519af"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
